{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer(风格迁移)\n",
    "---\n",
    "风格迁移（Style Transfer）是一种计算机视觉技术，旨在将一幅图像的艺术风格应用到另一幅图像的内容上，从而生成一幅新的图像，该图像既保留了内容图像的结构，又具有风格图像的艺术特征。风格迁移技术在深度学习领域得到了广泛的应用，尤其是在生成对抗网络（GANs）和卷积神经网络（CNNs）的发展中。\n",
    "\n",
    "## 基本概念\n",
    "- 内容图像（Content Image）：希望保留其主要结构和内容的图像。\n",
    "\n",
    "- 风格图像（Style Image）：希望应用其艺术风格的图像。\n",
    "\n",
    "- 生成图像（Generated Image）：最终生成的图像，结合了内容图像的结构和风格图像的艺术风格。\n",
    "\n",
    "## 核心思想\n",
    "风格迁移的核心思想是通过优化一个目标图像，使其在内容上接近内容图像，同时在风格上接近风格图像。这个优化过程通常涉及到以下几个步骤：\n",
    "1. 特征提取：\n",
    "\n",
    "    - 使用预训练的卷积神经网络（如VGG）从内容图像和风格图像中提取特征。\n",
    "\n",
    "    - 内容特征通常从网络的较深层提取，因为这些层捕捉了图像的高级结构信息。\n",
    "\n",
    "    - 风格特征通常从网络的多个层提取，因为这些层捕捉了图像的纹理和风格信息。\n",
    "\n",
    "2. 损失函数：\n",
    "\n",
    "    - 内容损失（Content Loss）：衡量生成图像与内容图像在内容上的相似度。\n",
    "\n",
    "    - 风格损失（Style Loss）：衡量生成图像与风格图像在风格上的相似度。\n",
    "\n",
    "    - 总变差损失（Total Variation Loss）：用于平滑生成图像，减少噪声。\n",
    "\n",
    "3. 优化过程：\n",
    "\n",
    "    通过梯度下降法（或其他优化算法）最小化总损失函数，逐步调整生成图像，使其在内容和风格上同时接近内容图像和风格图像。\n",
    "\n",
    "![Style Transfer](https://zh-v2.d2l.ai/_images/neural-style.svg \"ST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数\n",
    "1. 内容损失\n",
    "与线性回归中的损失函数类似，内容损失通过平方误差函数衡量合成图像与内容图像在内容特征上的差异。 平方误差函数的两个输入均为extract_features函数计算所得到的内容层的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def content_loss(Y_hat, Y):\n",
    "    # 我们从动态计算梯度的树中分离目标：\n",
    "    # 这是一个规定的值，而不是一个变量。\n",
    "    return torch.square(Y_hat - Y.detach()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 风格损失\n",
    "- 格拉姆矩阵（Gram Matrix）：\n",
    "\n",
    "    对于每一层的特征图，计算其格拉姆矩阵。格拉姆矩阵是一个矩阵，其元素表示特征图之间的内积，反映了特征图之间的相关性。\n",
    "\n",
    "    具体计算方法是将特征图展平为向量，然后计算这些向量之间的内积矩阵。\n",
    "\n",
    "- 风格损失计算：\n",
    "\n",
    "    对于每一层，计算生成图像和风格图像的格拉姆矩阵之间的均方误差（MSE）。\n",
    "\n",
    "    将所有层的风格损失加权求和，得到最终的风格损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def gram(X):\n",
    "    num_channels, n = X.shape[1], X.numel() // X.shape[1]\n",
    "    X = X.reshape((num_channels, n))\n",
    "    return torch.matmul(X, X.T) / (num_channels * n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 全变分损失\n",
    "有时候，我们学到的合成图像里面有大量高频噪点，即有特别亮或者特别暗的颗粒像素。 一种常见的去噪方法是全变分去噪（total variation denoising）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def tv_loss(Y_hat):\n",
    "    return 0.5 * (torch.abs(Y_hat[:, :, 1:, :] - Y_hat[:, :, :-1, :]).mean() +\n",
    "                  torch.abs(Y_hat[:, :, :, 1:] - Y_hat[:, :, :, :-1]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "风格转移的损失函数是内容损失、风格损失和总变化损失的加权和。 通过调节这些权重超参数，我们可以权衡合成图像在保留内容、迁移风格以及去噪三方面的相对重要性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "content_weight, style_weight, tv_weight = 1, 1e3, 10\n",
    "\n",
    "def compute_loss(X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram):\n",
    "    # 分别计算内容损失、风格损失和全变分损失\n",
    "    contents_l = [content_loss(Y_hat, Y) * content_weight for Y_hat, Y in zip(\n",
    "        contents_Y_hat, contents_Y)]\n",
    "    styles_l = [style_loss(Y_hat, Y) * style_weight for Y_hat, Y in zip(\n",
    "        styles_Y_hat, styles_Y_gram)]\n",
    "    tv_l = tv_loss(X) * tv_weight\n",
    "    # 对所有损失求和\n",
    "    l = sum(10 * styles_l + contents_l + [tv_l])\n",
    "    return contents_l, styles_l, tv_l, l"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
