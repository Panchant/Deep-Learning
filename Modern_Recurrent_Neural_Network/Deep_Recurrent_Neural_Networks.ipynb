{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深层循环神经网络（Deep RNN）\n",
    "\n",
    "深层循环神经网络（Deep Recurrent Neural Network, Deep RNN）是一种扩展的循环神经网络（RNN）架构，通过增加网络的深度来提高模型的表达能力和学习能力。深层RNN可以包含多个隐藏层，每个隐藏层都可以捕捉不同层次的特征和依赖关系。\n",
    "\n",
    "## 基本结构\n",
    "\n",
    "深层RNN的基本结构是在传统RNN的基础上增加多个隐藏层。每个隐藏层都可以有自己的循环连接，从而形成多层的循环结构。深层RNN可以分为两种主要类型：\n",
    "1. **堆叠RNN（Stacked RNN）**：多个RNN层按顺序堆叠，每一层的输出作为下一层的输入。\n",
    "2. **双向RNN（Bidirectional RNN）**：结合正向和反向的隐藏状态，捕捉序列中的双向依赖关系。\n",
    "\n",
    "## 数学表示\n",
    "\n",
    "假设输入序列为 \\( x_1, x_2, \\dots, x_T \\)，隐藏状态序列为 \\( h_1^{(1)}, h_2^{(1)}, \\dots, h_T^{(1)} \\)（第一层）， \\( h_1^{(2)}, h_2^{(2)}, \\dots, h_T^{(2)} \\)（第二层），依此类推。深层RNN的基本更新公式如下：\n",
    "\n",
    "1. **第一层隐藏状态更新**：\n",
    "\\[\n",
    "h_t^{(1)} = \\sigma(W_{hh}^{(1)} h_{t-1}^{(1)} + W_{xh}^{(1)} x_t + b_h^{(1)})\n",
    "\\]\n",
    "\n",
    "2. **第二层及以上隐藏状态更新**：\n",
    "\\[\n",
    "h_t^{(l)} = \\sigma(W_{hh}^{(l)} h_{t-1}^{(l)} + W_{h^{(l-1)}h^{(l)}} h_t^{(l-1)} + b_h^{(l)})\n",
    "\\]\n",
    "\n",
    "其中：\n",
    "- \\( h_t^{(l)} \\) 是第 \\( l \\) 层在时间步 \\( t \\) 的隐藏状态。\n",
    "- \\( W_{hh}^{(l)} \\)、\\( W_{xh}^{(1)} \\)、\\( W_{h^{(l-1)}h^{(l)}} \\) 是权重矩阵。\n",
    "- \\( b_h^{(l)} \\) 是偏置项。\n",
    "- \\( \\sigma \\) 是激活函数（如tanh或ReLU）。\n",
    "\n",
    "![DRNN](https://zh-v2.d2l.ai/_images/deep-rnn.svg \"DRNN\")\n",
    "## 特点\n",
    "\n",
    "1. **多层结构**：通过增加隐藏层的数量，深层RNN能够捕捉更复杂的特征和依赖关系。\n",
    "2. **参数共享**：每一层的RNN单元共享相同的权重矩阵，减少了参数数量，便于训练。\n",
    "3. **双向信息流动**：双向RNN能够结合正向和反向的隐藏状态，捕捉序列中的双向依赖关系。\n",
    "\n",
    "## 应用\n",
    "\n",
    "深层RNN广泛应用于各种序列建模任务，特别是在需要捕捉复杂依赖关系的场景中：\n",
    "- **语言模型**：预测下一个词或字符的概率。\n",
    "- **机器翻译**：将一种语言的句子翻译成另一种语言。\n",
    "- **语音识别**：将语音信号转换为文本。\n",
    "- **时间序列预测**：如股票价格预测、天气预报等。\n",
    "\n",
    "\n",
    "**注：**   该代码与之前LSTM使用的代码非常相似， 实际上唯一的区别是我们指定了层的数量， 而不是使用单一层这个默认值"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
