{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 序列模型(Sequence Model)\n",
    "---\n",
    "序列模型（Sequence Model）是一类在数据具有时间序列或顺序关系时应用的模型。典型的序列模型包括传统的统计模型和深度学习模型，它们主要处理的数据类型如时间序列数据、文本数据、音频数据等，强调输入数据的顺序和上下文信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见的序列模型类型\n",
    "1. 马尔可夫链（Markov Chain）\n",
    "- 这是最基础的序列模型之一，它假设当前状态只依赖于前一个状态（即一阶马尔可夫链），或者依赖于有限几个之前的状态。\n",
    "\n",
    "2. 隐马尔可夫模型（Hidden Markov Model, HMM）\n",
    "- 隐马尔可夫模型是马尔可夫链的扩展，它考虑观察到的序列是由一组隐藏的状态通过一定概率生成的。这种模型常用于语音识别、手写识别和序列标注等任务。\n",
    "\n",
    "3. 自回归模型（Autoregressive Model, AR）\n",
    "- 在时间序列分析中，自回归模型是一种假设当前值是之前值的线性组合的模型，例如ARIMA模型常用于时间序列预测。\n",
    "\n",
    "4. 递归神经网络（Recurrent Neural Network, RNN）\n",
    "- RNN是深度学习中的经典序列模型，它通过循环结构使得网络能够记住之前的输入，从而处理具有顺序关系的数据。基本RNN的缺点是无法很好地捕捉长时间依赖。\n",
    "\n",
    "5. 长短时记忆网络（Long Short-Term Memory, LSTM）\n",
    "- LSTM是一种改进的RNN，解决了基本RNN在处理长序列时的梯度消失问题。LSTM通过引入“记忆单元”来长期保持重要信息。\n",
    "\n",
    "6. 门控循环单元（Gated Recurrent Unit, GRU）\n",
    "- GRU是LSTM的一种简化版本，同样能够捕捉长时间的依赖关系，但结构更为简洁，计算成本较低。\n",
    "\n",
    "7. 卷积神经网络（CNN）在序列建模中的应用\n",
    "- 尽管CNN最初用于图像处理，它同样可以用于一维序列数据。例如，文本分类任务中，CNN可以通过一维卷积捕获局部序列模式。\n",
    "\n",
    "8. Transformer模型\n",
    "- Transformer模型是近年来深度学习中最受关注的序列模型，它摒弃了传统的循环结构，而是基于注意力机制来捕获序列中全局的依赖关系。Transformer及其变种（如BERT、GPT等）在自然语言处理和其他序列任务中取得了显著成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**训练代码可参考:**  [序列模型](https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/sequence.html \"序列模型\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
