{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trans Convolution\n",
    "---\n",
    "\n",
    "## 什么是转置卷积\n",
    "我理解转置卷积是卷积的反面。在卷积层中，我们使用一种名为互相关的特殊操作（在机器学习中，该操作通常称为卷积，因此这些层被称为“卷积层”）来计算输出值。此操作将输入层中的所有相邻数字相加，并由卷积矩阵（内核）加权。例如，在下图中，输出值55是通过输入层的 3x3 部分与 3x3 内核之间的元素乘法计算得出的，然后将所有结果相加：\n",
    "\n",
    "![dsa](https://miro.medium.com/v2/resize:fit:2000/format:webp/1*ipFlC0AF9qR2MJc07YGT7g.png \"1\")\n",
    "![ss](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iSK6zvCLfbPt7HKlODreJA.png \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无需任何填充，此操作即可将 4x4 矩阵转换为 2x2 矩阵。这看起来就像有人从左向右投射光线，并将一个物体（4x4 矩阵）投射到一个孔（3x3 核）中，从而产生一个较小的物体（2x2 矩阵）。现在，我们的问题是：如果我们想从 2x2 矩阵逆向到 4x4 矩阵该怎么办？嗯，直观的方法是，我们只需将光线向后投射！从数学上讲，我们不必将两个 3x3 矩阵相乘，而是将输入层中的每个值乘以 3x3 内核，以得到一个 3x3 矩阵。然后，我们只需根据输入层中的初始位置将它们全部组合在一起，然后将重叠的值相加：\n",
    "![ds](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eeMbMohZF-K3OsAlbiJBZA.png \"2\")\n",
    "![d](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ZIkJlNGsb-fNdNfAy25oA.png \"3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样，转置卷积运算的输出可以具有与前一个卷积运算的输入完全相同的形状，因为我们只是做了完全相反的事情。但是，您可能会注意到数字并没有恢复。因此，必须使用完全不同的内核来恢复初始输入矩阵，并且可以通过训练确定此内核。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你可能会想：嘿，这看起来就像一个反向卷积。为什么它被称为“转置”卷积？\n",
    "一篇名为“使用转置卷积进行上采样”的文章对我帮助很大。在这篇文章中，作者 Naoki Shibuya 使用零填充卷积矩阵而不是普通的方形卷积矩阵来表示卷积运算。本质上，在执行卷积变换时，我们可以将上述内核表示为 4x16 矩阵，而不是将上述内核表示为 3x3 矩阵。并且，我们可以将上述输入表示为 16x1 向量，而不是 4x4 矩阵：\n",
    "![ds](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aNWGUBAFLC1qbW4ic4gW0A.png \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它之所以是 4x16 矩阵是因为：\n",
    "- 4 行：总共，我们可以通过将 4x4 输入矩阵分成四个 3x3 矩阵来执行四次卷积；\n",
    "- 16 列：输入矩阵将转换为 16x1 向量。要执行矩阵乘法，它必须是 16 列。\n",
    "\n",
    "![ds](https://miro.medium.com/v2/resize:fit:646/format:webp/1*_TBSy9hUD7xnmtEo1EMKdA.png \"sd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样，我们就可以直接进行矩阵乘法来得到输出层。重新整形后的输出层将与一般卷积运算得到的输出层完全相同。\n",
    "![dasd](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ju7a4yfYP2G5ocPBBFj0zQ.png \"dfa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们执行转置卷积运算时，我们只是简单地转置零填充的卷积矩阵并将其与输入向量（即卷积层的输出）相乘。在下图中，中间阶段的四个彩色向量表示矩阵乘法的中间步骤：\n",
    "![sda](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5aATfUyJcgCD_X2J4xGwzg.png \"ds \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们重新排列中间阶段的四个向量，我们将得到四个 4x4 矩阵，它们的数字与我们将 3x3 内核与输入层中的每个元素相乘而得到的 3x3 矩阵完全相同，多余的位置用零填充。这四个矩阵也可以进一步组合以得到最终的 4x4 输出矩阵：\n",
    "![ff](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ag2TnDek0KrgJ3gcvmE7vw.png \"dsad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dadsa](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qUZxyunJ_s4xxbgKcbwgmQ.png \"sdad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，该操作被称为“转置”卷积，因为除了转置卷积矩阵之外，我们执行了完全相同的操作！\n",
    "\n",
    "\n",
    "\n",
    "**参考来源:** [Understand Transposed Convolutions](https://towardsdatascience.com/understand-transposed-convolutions-and-build-your-own-transposed-convolution-layer-from-scratch-4f5d97b2967 \"Understand Transposed Convolutions\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
